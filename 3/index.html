<link rel="stylesheet" href="../style.css">
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project 3 — CS180 / 280A</title>
  <meta name="description" content="Project 3 write-up for CS180/280A: Image Warping and Mosaicing." />
  <script src="https://unpkg.com/lucide@latest"></script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(', '\\)'], ['$', '$']],
        displayMath: [['\\[', '\\]'], ['$$', '$$']]
      },
      options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
  <div class="wrap">
    <header>
      <div class="brand">Brandon Xu</div>
      <div class="subtitle">CS180 / 280A • Fall 2025</div>
      <nav>
        <a href="../index.html">← Back to Portfolio</a>
        <button class="theme-toggle" type="button" aria-label="Toggle theme" title="Toggle theme">
          <i data-lucide="sun" class="icon-sun"></i>
          <i data-lucide="moon" class="icon-moon"></i>
        </button>
      </nav>
    </header>

    <main>
      <h1>Project 3 — Image Warping and Mosaicing</h1>

      <section class="gallery-text">
        <h2>Project Overview</h2>
        <p>
          The goal of this project is to create image mosaics by registering, warping, resampling, and compositing
          multiple photographs. This involves computing homographies to perform projective transformations and
          blending images seamlessly. Throughout this project, I implement homography computation, image warping
          with different interpolation methods, and image blending techniques to create panoramic mosaics.
        </p>
      </section>

      <!-- Part A.1: Shoot and Digitize Pictures -->
      <section>
        <h2>Part A.1: Shoot and Digitize Pictures</h2>

        <div class="gallery-text">
          <h3>Image Set 1</h3>
          <p>Here are some pictures that I shot inside an apartment.
            These are examples of projective transformations, where the center of projection was fixed, but the camera
            was rotated to be able to capture different views of the scene.</p>
        </div>
        <figure>
          <img src="./outputs/image_set_1_overview.png" alt="Set 1 Image 1" loading="lazy">
        </figure>
        <div class="gallery-text">
          <h3>Image Set 2</h3>
          <p>Here are some pictures that I shot inside Main Stacks.
        </div>
        <figure>
          <img src="./outputs/image_set_2_overview.png" alt="Set 1 Image 1" loading="lazy">
        </figure>
        <div class="gallery-text">
          <h3>Image Set 3</h3>
          <p>Here are some more photos that I shot inside Main Stacks.
        </div>
        <figure>
          <img src="./outputs/image_set_3_overview.png" alt="Set 1 Image 1" loading="lazy">
        </figure>
        <!-- Part A.2: Recover Homographies -->
        <section>
          <h2>Part A.2: Recover Homographies</h2>

          <div class="gallery-text">
            <h3>Overview</h3>
            <p>
              This portion of the project involved constructing 3×3 homography matrices to map coordinates from one
              plane to another.
              The transformation is written as <code>A&nbsp;x&nbsp;=&nbsp;b</code>, where <code>x</code> contains the
              eight unknown
              parameters of the homography (the ninth entry is fixed to 1). Specifically, <code>x[0:3]</code>
              corresponds to the first row,
              <code>x[3:6]</code> to the second row, and <code>x[6:8] + [1]</code> to the third row of the matrix.
            </p>

            <h3>Implementation</h3>
            <p>
              To solve for <code>x</code>, a least-squares approach is used because relying on only four point
              correspondences is unstable.
              Additional correspondences are therefore incorporated to improve robustness.
            </p>
            <p>
              For each correspondence between a point <code>im1_point = (x, y)</code> in the first image and
              <code>im2_point = (x′, y′)</code> in the second image, two rows are added to <code>A</code> and two
              entries to <code>b</code>:
            </p>
            <p style="margin: 0.75rem 0;">
              <strong>Row 1 of A:</strong>
              <code>[x, y, 1, 0, 0, 0, -x′·x, -x′·y]</code><br>
              <strong>Row 2 of A:</strong>
              <code>[0, 0, 0, x, y, 1, -y′·x, -y′·y]</code><br>
              <strong>Corresponding entries in b:</strong>
              <code>[x′, y′]</code>
            </p>
            <p>
              Here, <code>im1_point</code> and <code>im2_point</code> represent matching (x, y) coordinates in
              Image&nbsp;1 and Image&nbsp;2,
              respectively. This process is repeated for all point pairs, accumulating two equations per correspondence,
              and the resulting
              overdetermined system <code>A&nbsp;x&nbsp;=&nbsp;b</code> is solved in the least-squares sense to obtain
              the homography.
            </p>

            <h3>Point Correspondences</h3>
            <p>
              The figures illustrate the correspondences between the two images.
            </p>
          </div>
          <figure>
            <img src="./outputs/correspondence_points_set3.png" loading="lazy">
          </figure>

          <h3>Computed Matrices</h3>

          <p>
            The following matrices show the results of the homography computation.
            The <strong>A</strong> matrix represents the system coefficients,
            <strong>b</strong> is the vector of corresponding image coordinates,
            and <strong>H</strong> is the resulting 3×3 homography matrix.
          </p>

          <div style="margin: 1.5rem 0;">
            <h4 style="margin-bottom: 0.5rem;">A Matrix</h4>
            <pre style="
              background-color: #1e1e1e;
              color: #dcdcdc;
              padding: 1rem;
              border-radius: 8px;
              overflow-x: auto;
              font-size: 0.85rem;
            ">
              [[ 1.4900e+02 9.0000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.2814e+04 -7.7400e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.4900e+02 9.0000e+01 1.0000e+00 -1.2963e+04 -7.8300e+03]
              [ 1.4700e+02 1.3200e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.2936e+04 -1.1616e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.4700e+02 1.3200e+02 1.0000e+00 -1.8963e+04 -1.7028e+04]
              [ 1.4700e+02 1.7200e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.2789e+04 -1.4964e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.4700e+02 1.7200e+02 1.0000e+00 -2.4990e+04 -2.9240e+04]
              [ 1.4600e+02 2.1100e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.2848e+04 -1.8568e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.4600e+02 2.1100e+02 1.0000e+00 -3.0368e+04 -4.3888e+04]
              [ 8.0000e+01 9.6000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -8.8000e+02 -1.0560e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 8.0000e+01 9.6000e+01 1.0000e+00 -7.1200e+03 -8.5440e+03]
              [ 9.4000e+01 1.4200e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.7260e+03 -4.1180e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 9.4000e+01 1.4200e+02 1.0000e+00 -1.3160e+04 -1.9880e+04]
              [ 1.8000e+02 1.0600e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1240e+04 -1.2508e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.8000e+02 1.0600e+02 1.0000e+00 -1.8900e+04 -1.1130e+04]
              [ 1.7900e+02 1.3500e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1301e+04 -1.6065e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.7900e+02 1.3500e+02 1.0000e+00 -2.3628e+04 -1.7820e+04]
              [ 1.7900e+02 1.6300e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1122e+04 -1.9234e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.7900e+02 1.6300e+02 1.0000e+00 -2.8640e+04 -2.6080e+04]
              [ 1.7800e+02 1.9100e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1004e+04 -2.2538e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.7800e+02 1.9100e+02 1.0000e+00 -3.3286e+04 -3.5717e+04]
              [ 1.7900e+02 2.2000e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1301e+04 -2.6180e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.7900e+02 2.2000e+02 1.0000e+00 -3.8306e+04 -4.7080e+04]
              [ 2.1200e+02 7.7000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -3.1376e+04 -1.1396e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 2.1200e+02 7.7000e+01 1.0000e+00 -1.6748e+04 -6.0830e+03]
              [ 1.5900e+02 6.2000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.5264e+04 -5.9520e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.5900e+02 6.2000e+01 1.0000e+00 -9.5400e+03 -3.7200e+03]
              [ 1.8000e+02 8.2000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.1240e+04 -9.6760e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.8000e+02 8.2000e+01 1.0000e+00 -1.4760e+04 -6.7240e+03]
              [ 1.7700e+02 2.6600e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.0886e+04 -3.1388e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.7700e+02 2.6600e+02 1.0000e+00 -4.5843e+04 -6.8894e+04]
              [ 1.2000e+02 2.7000e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -7.3200e+03 -1.6470e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.2000e+02 2.7000e+02 1.0000e+00 -3.2640e+04 -7.3440e+04]
              [ 2.0800e+02 2.2700e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -3.0368e+04 -3.3142e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 2.0800e+02 2.2700e+02 1.0000e+00 -4.5552e+04 -4.9713e+04]
              [ 1.2400e+02 7.0000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -7.3160e+03 -4.1300e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.2400e+02 7.0000e+01 1.0000e+00 -7.9360e+03 -4.4800e+03]
              [ 1.2200e+02 1.2200e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -7.3200e+03 -7.3200e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.2200e+02 1.2200e+02 1.0000e+00 -1.4518e+04 -1.4518e+04]
              [ 1.2100e+02 1.7200e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -7.3810e+03 -1.0492e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.2100e+02 1.7200e+02 1.0000e+00 -2.0691e+04 -2.9412e+04]
              [ 1.2100e+02 2.2000e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -7.3810e+03 -1.3420e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.2100e+02 2.2000e+02 1.0000e+00 -2.6741e+04 -4.8620e+04]
              [ 2.0200e+02 2.7100e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.8482e+04 -3.8211e+04]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 2.0200e+02 2.7100e+02 1.0000e+00 -5.2722e+04 -7.0731e+04]
              [ 1.9800e+02 5.3000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.6532e+04 -7.1020e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.9800e+02 5.3000e+01 1.0000e+00 -1.1088e+04 -2.9680e+03]
              [ 1.4200e+02 4.6000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -1.1360e+04 -3.6800e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.4200e+02 4.6000e+01 1.0000e+00 -6.1060e+03 -1.9780e+03]
              [ 1.8800e+02 3.5000e+01 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 -2.3312e+04 -4.3400e+03]
              [ 0.0000e+00 0.0000e+00 0.0000e+00 1.8800e+02 3.5000e+01 1.0000e+00 -6.7680e+03 -1.2600e+03]]
            </pre>
          </div>

          <div style="margin: 1.5rem 0;">
            <h4 style="margin-bottom: 0.5rem;">b Matrix</h4>
            <pre style="
              background-color: #1e1e1e;
              color: #dcdcdc;
              padding: 1rem;
              border-radius: 8px;
              overflow-x: auto;
              font-size: 0.85rem;
            ">
          [ 86.  87.  88. 129.  87. 170.  88. 208.  11.  89.  29. 140. 118. 105.
          119. 132. 118. 160. 118. 187. 119. 214. 148.  79.  96.  60. 118.  82.
          118. 259.  61. 272. 146. 219.  59.  64.  60. 119.  61. 171.  61. 221.
          141. 261. 134.  56.  80.  43. 124.  36.]
            </pre>
          </div>

          <div style="margin: 1.5rem 0;">
            <h4 style="margin-bottom: 0.5rem;">H Matrix</h4>
            <pre style="
              background-color: #1e1e1e;
              color: #00ffcc;
              padding: 1rem;
              border-radius: 8px;
              overflow-x: auto;
              font-size: 0.95rem;
            ">
          [[ 1.37670896e+00  3.17739065e-02 -1.00864074e+02]
          [ 2.06032825e-01  1.23866833e+00 -3.51875841e+01]
          [ 1.47286400e-03  5.77021348e-05  1.00000000e+00]]
            </pre>
          </div>

        </section>

        <!-- Part A.3: Warp the Images -->
        <section>
          <h2>Part A.3: Warp the Images</h2>

          <div class="gallery-text">
            <h3>Overview</h3>
            <p>
              Using the computed homographies, I warped images to align them with a reference frame. I implemented
              inverse warping to avoid holes in the output. For each pixel in the output image, I compute its
              corresponding location in the input image using \(H^{-1}\) and sample the color value using interpolation.
            </p>

            <h3>Implementation</h3>
            <p>
              I implemented two interpolation methods:
            </p>
            <ul>
              <li>
                <strong>Nearest Neighbor:</strong> Round the computed coordinates to the nearest integer pixel position.
                This is fast but can produce blocky artifacts.
              </li>
              <li>
                <strong>Bilinear Interpolation:</strong> Compute a weighted average of the four neighboring pixels
                based on the fractional part of the coordinates. This produces smoother results but is computationally
                more expensive.
              </li>
            </ul>

            <h3>Bounding Box Computation</h3>
            <p>
              To determine the output image size, I transformed the four corners of the input image through the
              homography and computed the bounding box of the warped corners. I also maintained an alpha channel
              to track which pixels contain valid image data.
            </p>

            <h3>Rectification Examples</h3>
            <p>
              Before creating full mosaics, I tested the warping pipeline by rectifying rectangular objects in
              photographs. By defining correspondences between a tilted rectangle and a canonical square, I can
              "straighten" the object.
            </p>
          </div>
          <h3>Rectification on Images from Part 1 and 2</h3>
          <figure>
            <img src="./outputs/set1/im1.jpeg" loading="lazy">
            <figcaption>Rectification Example 1 - Original</figcaption>
          </figure>
          <figure>
            <img src="./outputs/warped_nn_set3.png" loading="lazy">
            <figcaption>Rectification Example 1 - Nearest Neighbor</figcaption>
          </figure>
          <figure>
            <img src="./outputs/warped_bilinear_set3.png" loading="lazy">
            <figcaption>Rectification Example 1 - Bilinear</figcaption>
          </figure>

          <h3>Rectification on a Parcel</h3>
          <figure>
            <img src="./outputs/rec3.jpeg" loading="lazy">
            <figcaption>Rectification Example 1 - Original</figcaption>
          </figure>
          <figure>
            <img src="./outputs/parcel_warped_nn.png" loading="lazy">
            <figcaption>Rectification using NN</figcaption>
          </figure>
          <figure>
            <img src="./outputs/parcel_warped_bilinear.png" loading="lazy">
            <figcaption>Rectification using Bilinear</figcaption>
          </figure>
          <figure>
            <img src="./outputs/parcel_warped_nn_rectified.png" loading="lazy">
            <figcaption>Zoomed in NN Rectification</figcaption>
          </figure>
          <figure>
            <img src="./outputs/parcel_warped_bilinear_rectified.png" loading="lazy">
            <figcaption>Zoomed in Bilinear Rectification</figcaption>
          </figure>

          <h3>Rectification on a Squidward Photo</h3>

          <figure>
            <img src="./outputs/rec4.jpeg" loading="lazy">
            <figcaption>Original Image</figcaption>
          </figure>
          <figure>
            <img src="./outputs/squidward_warped_nn.png" loading="lazy">
            <figcaption>Rectification using NN</figcaption>
          </figure>
          <figure>
            <img src="./outputs/squidward_warped_bilinear.png" loading="lazy">
            <figcaption>Rectification using Bilinear</figcaption>
          </figure>
          <figure>
            <img src="./outputs/squidward_warped_nn_rectified.png" loading="lazy">
            <figcaption>Zoomed in NN Rectification</figcaption>
          </figure>
          <figure>
            <img src="./outputs/squidward_warped_bilinear_rectified.png" loading="lazy">
            <figcaption>Zoomed in Bilinear Rectification</figcaption>
          </figure>

          <div class="gallery-text">
            <h3>Interpolation Comparison</h3>
            <p>
              Both methods had their own trade-offs. The nearest-neighbor approach was slightly faster and produced
              sharper results, though it tended to be slightly less smooth than bilinear interpolation. In contrast,
              bilinear interpolation yielded a softer, more blended appearance, but the nearest-neighbor results were
              still reasonably smooth overall.
            </p>
          </div>
        </section>

        <!-- Part A.4: Blend Images into Mosaics -->
        <section>
          <h2>Part A.4: Blend Images into Mosaics</h2>

          <div class="gallery-text">
            <h3>Overview</h3>
            <p>
              This part focused on blending multiple images into a single mosaic. I began by computing a homography
              using
              corresponding points between two images, allowing me to warp one image into the coordinate frame of the
              other.
              The warped image and the reference image were then placed on a larger canvas, with offsets adjusted to
              align them
              properly.
            </p>

            <h3>Blending Process</h3>
            <p>
              Initially, combining images by direct pixel replacement caused visible seams at the boundaries. To fix
              this, I
              implemented distance-based alpha blending. Each image had an alpha mask where pixels near the center had
              higher
              weights and pixels near the edges had lower weights, computed using a distance transform. In overlapping
              regions,
              pixel values were blended using a weighted average of the contributing images based on these alpha values.
            </p>

            <p>
              The final blending equation was:
              \[
              I_{\text{final}}(x,y) = \frac{\sum_i \alpha_i(x,y) \cdot I_i(x,y)}{\sum_i \alpha_i(x,y)}
              \]
              where \(\alpha_i\) represents the distance-based weight for each image. This produced smooth, seamless
              transitions
              between overlapping regions.
            </p>
          </div>

          <h3>Mosaic 1</h3>
          <h4>Source Images</h4>
          <div class="gallery-text">
            <figure>
              <img src="./outputs/set1/im1.jpeg" alt="Mosaic 1 Source 1" loading="lazy">
              <figcaption>Mosaic 1 - Source Image 1</figcaption>
            </figure>
            <figure>
              <img src="./outputs/set1/im2.jpeg" alt="Mosaic 1 Source 2" loading="lazy">
              <figcaption>Mosaic 1 - Source Image 2</figcaption>
            </figure>

            <h4>Warped Image</h4>
            <figure>
              <img src="./outputs/warped_nn_set3.png" loading="lazy">
              <figcaption>Warped Image</figcaption>
            </figure>

            <h4>Final Mosaic Result</h4>
            <figure>
              <img src="./outputs/mosaic_1_bilinear.png" loading="lazy">
              <figcaption>Mosaic 1 - Bilinear Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_1_nn.png" loading="lazy">
              <figcaption>Mosaic 1 - NN Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_1_no_blend.png" loading="lazy">
              <figcaption>Mosaic 1 - No Blend Final Result</figcaption>
            </figure>
          </div>

          <h3>Mosaic 2</h3>

          <h4>Source Images</h4>
          <div class="gallery-text">
            <figure>
              <img src="./outputs/set2/im1.jpeg" loading="lazy">
              <figcaption>Mosaic 2 - Source Image 1</figcaption>
            </figure>
            <figure>
              <img src="./outputs/set2/im2.jpeg" loading="lazy">
              <figcaption>Mosaic 2 - Source Image 2</figcaption>
            </figure>

            <h4>Warped Image</h4>
            <figure>
              <img src="./outputs/warped_set2.png" loading="lazy">
              <figcaption>Warped Image</figcaption>
            </figure>

            <h4>Final Mosaic Result</h4>
            <figure>
              <img src="./outputs/mosaic_2_bilinear.png" loading="lazy">
              <figcaption>Mosaic 2 - Bilinear Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_2_nn.png" loading="lazy">
              <figcaption>Mosaic 2 - NN Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_2_no_blend.png" loading="lazy">
              <figcaption>Mosaic 2 - No Blend Final Result</figcaption>
            </figure>
          </div>

          <h3>Mosaic 3: </h3>

          <h4>Source Images</h4>
          <div class="gallery-text">
            <figure>
              <img src="./outputs/set3/im1.jpeg" loading="lazy">
              <figcaption>Mosaic 3 - Source Image 1</figcaption>
            </figure>
            <figure>
              <img src="./outputs/set3/im2.jpeg" loading="lazy">
              <figcaption>Mosaic 3 - Source Image 2</figcaption>
            </figure>

            <h4>Warped Image</h4>
            <figure>
              <img src="./outputs/warped_set1.png" loading="lazy">
              <figcaption>Warped Image</figcaption>
            </figure>

            <h4>Final Mosaic Result</h4>
            <figure>
              <img src="./outputs/mosaic_3_bilinear.png" loading="lazy">
              <figcaption>Mosaic 3 - Bilinear Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_3_nn.png" loading="lazy">
              <figcaption>Mosaic 3 - NN Final Result</figcaption>
            </figure>

            <figure>
              <img src="./outputs/mosaic_3_no_blend.png" loading="lazy">
              <figcaption>Mosaic 3 - No Blend Final Result</figcaption>
            </figure>
          </div>
        </section>

        <section>
          <h2>Part B.1: Harris Corner Detection</h2>
          <p>Because the implementation for Harris Corners was provided most of the work in this part focused on ANMS.
            Since raw Harris corners clump in textured regions, I apply ANMS with N=500 and c=0.9: for each
            candidate I compute a suppression radius to the nearest corner that’s at least 1/c ≈ 1.11× stronger, and I
            keep the 500 largest radii so the final keypoints are strong and spatially well-distributed. The c=0.9
            setting is a mild strictness that still lets slightly weaker neighbors survive if they’re far enough away,
            and N=500 balances coverage with descriptor/matching cost. In the end, I receive an image that is well
            spread out with its points.</p>
          <div class="gallery-text">
            <h3>Harris Corners and ANMS on Mosaic 1, Image 1</h3>
            <figure>
              <img src="./outputs2/anms_corners_image1.png" loading="lazy">
            </figure>
            <h3>Harris Corners and ANMS on Mosaic 1, Image 2</h3>
            <figure>
              <img src="./outputs2/anms_corners_image2.png" loading="lazy">
            </figure>
          </div>
        </section>

        <section>
          <h2>Part B.2: Feature Descriptor Extraction</h2>
          <p>For each ANMS keypoint (r, c), I convert to grayscale and smooth with a Gaussian, which reduces
            high-frequency noise and makes
            the descriptor more robust to small misalignments. I then extract a 40×40 patch with patch_radius=20
            (skipping points too close to the border), downsample it to 8×8 to get a
            compact 64-D vector, and standardize each patch by subtracting its mean and dividing by its std. The 40 to 8
            downsampling captures coarse structure (edges/corners/blobs) while discarding
            fine detail that doesn’t transfer reliably across views, and the zero-mean/unit-variance normalization gives
            some invariance to affine intensity changes. The
            ksize=30, sigma=5 Gaussian is wide enough to attenuate pixel-level noise but not so wide that it washes out
            the corner structure that Harris selected.</p>
          <div class="gallery-text">
            <h3>Feature Descriptors on Mosaic 1, Image 1</h3>
            <figure>
              <img src="./outputs2/feature_descriptors.png" loading="lazy">
            </figure>
          </div>
        </section>

        <section>
          <h2>Part B.3: Feature Matching</h2>
          <p>I match features by computing the full pairwise squared Euclidean distance matrix, and, for each
            descriptor, I find the two nearest neighbors best and second. I apply Lowe’s ratio with a ratio thereshold
            of 0.7 and a tiny error 1e-12 in the denominator for numerical safety; this rejects ambiguous matches in
            repetitive textures where the top two candidates are almost equally close. I used 0.7 as a threshold because
            it is a conservative choice that
            prunes many false positives while typically keeping enough correspondences for robust RANSAC. I then return
            only the indices
            that pass the
            ratio test and visualize them so I can sanity-check coverage and spatial distribution before estimating
            geometry.</p>
          <div class="gallery-text">
            <h3>Feature Descriptors on Mosaic 1, Image 1</h3>
            <figure>
              <img src="./outputs2/matched_correspondences.png" loading="lazy">
            </figure>
          </div>
        </section>

        <section>
          <h2>Part B.4: RANSAC for Robust Homography</h2>
          <p>Starting from the tentative matches, I estimate a homography with RANSAC using iterations=10000 and an
            inlier threshold=3.0 pixels: I repeatedly sample 4 correspondences, compute H with my computeH DLT
            least-squares solver, measure reprojection error on all matches, and keep the model with the largest inlier
            set. The 3-pixel cutoff reflects a balance between measurement noise (blurry or downsampled keypoints,
            descriptor quantization) and real geometric deviations; smaller thresholds risk rejecting good points, while
            larger ones admit more outliers. After RANSAC, I refit H on just the inliers to reduce bias from the random
            minimal sample and to get the best possible estimate for warping. In auto_stitching, I used a
            matching_threshold=0.7, ransac_threshold=3.0, and ransac_iterations=10000—so I can trade speed
            for robustness depending on the image pair. Finally, I mosaic the images using my Part-A compositor
            (mosaic_NN) fed by the RANSAC inliers. This setup yields an end-to-end automatic stitcher that handles
            outliers gracefully and produces stable panoramas without manual correspondences.</p>

          <p> When comparing the automatic stitching results to the manual correspondences from Part A, I observed that
            the RANSAC-based mosaics were
            generally quite good, though due to the quality/size of my images it is hard to tell if there is a
            meaningful difference.
            RANSAC can only work with the features it detects, which may not cover all the ideal
            areas for alignment, which may result in not perfect alignment. However, the automatic approach is much more
            scalable and requires no user input,
            making it suitable for a wide range of images. Overall, the RANSAC mosaics were satisfactory and
            demonstrated the effectiveness of robust estimation in practical scenarios.</p>
          <div class="gallery-text">
            <h3>RANSAC on Mosaic 1</h3>
            <figure>
              <img src="./outputs2/ransac_inliers_0.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs2/auto_mosaic_set3.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs/mosaic_1_nn.png" loading="lazy">
            </figure>
          </div>
          <div class="gallery-text">
            <h3>RANSAC on Mosaic 2</h3>
            <figure>
              <img src="./outputs2/ransac_inliers_1.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs2/auto_mosaic_set2.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs/mosaic_2_nn.png" loading="lazy">
            </figure>
          </div>
          <div class="gallery-text">
            <h3>RANSAC on Mosaic 3</h3>
            <figure>
              <img src="./outputs2/ransac_inliers_2.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs2/auto_mosaic_set1.png" loading="lazy">
            </figure>
            <figure>
              <img src="./outputs/mosaic_3_nn.png" loading="lazy">
            </figure>
          </div>
        </section>
    </main>

    <footer>
      <p>
        Built with plain HTML & CSS. Hosted on GitHub Pages.
        <a href="https://cal-cs180.github.io/fa25/hw/proj3/partA.html">Assignment details</a>.
      </p>
    </footer>
  </div>

  <script>
    const root = document.documentElement;

    function getInitialTheme() {
      const systemPrefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      const saved = localStorage.theme;
      return saved || (systemPrefersDark ? 'dark' : 'light');
    }

    function applyTheme(theme) {
      root.setAttribute('data-theme', theme);
      localStorage.theme = theme;
    }

    function updateToggleIcons() {
      const current = root.getAttribute('data-theme') || getInitialTheme();
      document.querySelectorAll('.theme-toggle').forEach((btn) => {
        btn.innerHTML = `<i data-lucide="${current === 'dark' ? 'sun' : 'moon'}"></i>`;
      });
      if (window.lucide && typeof window.lucide.createIcons === 'function') {
        window.lucide.createIcons();
      }
    }

    // Initialize
    applyTheme(getInitialTheme());
    updateToggleIcons();

    // Wire up events for all toggles
    document.querySelectorAll('.theme-toggle').forEach((btn) => {
      btn.addEventListener('click', () => {
        const current = root.getAttribute('data-theme');
        const next = current === 'dark' ? 'light' : 'dark';
        applyTheme(next);
        updateToggleIcons();
      });
    });
  </script>
</body>

</html>